{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# https://docs.python.org/3/library/io.html\n",
    "import io\n",
    "import os\n",
    "\n",
    "# https://python-guide-pt-br.readthedocs.io/fr/latest/scenarios/imaging.html\n",
    "from PIL import Image \n",
    "\n",
    "# https://docs.python.org/fr/3/library/hashlib.html\n",
    "import hashlib # permet de chiffrer \n",
    "\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    " \n",
    "# selenium package\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import multiprocessing\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "# beautiful soup\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "\n",
    "# image traitement et features extraction\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn import mixture\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "### SVM\n",
    "from sklearn import neighbors, datasets, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, recall_score, r2_score, mean_absolute_error, mean_squared_error, mean_absolute_error\n",
    "##SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "images_per_class = 80\n",
    "fixed_size = tuple((56, 56))\n",
    "MAINDIR='C:/Users/utilisateur/Documents/DataIA/Projet/Projet_Classification_ZARA/Algo/'\n",
    "DATADIR=MAINDIR + 'images_without_models/' # répertoire contenant les images réparties  dans les dossiers categories\n",
    "CATEGORIES=os.listdir(DATADIR) #ie : jupes, pantalons, robes, t-shirts (attention j'ai un s à la fin des termes)\n",
    "image_test='C:/Users/utilisateur/Documents/DataIA/Projet/Projet_Classification_ZARA/Algo/Images/jupes/jupe_0.jpg'\n",
    "####################################\n",
    "\n",
    "\n",
    "\n",
    "############### FONCTION POUR RENOMMER LES IMAGES en \"category\"_xx.jpg #########################\n",
    "def rename_file(CATECORIES):\n",
    "    for category in CATECORIES:\n",
    "        path=DATADIR+category\n",
    "        for i, filename in enumerate(os.listdir(path)):\n",
    "            os.rename(path + \"/\" + filename, path + \"/\" + category[:-1]+'_'+ str(i) + \".jpg\") # folder[:-1] c'est juste pour enlever le s\n",
    "            # output = jupe_0.jpg ; jupe_1.jpg etc...\n",
    "\n",
    "################# traitement d'une image ###################\n",
    "def traitement_image(image_path):\n",
    "    ### Load image ###\n",
    "    img = cv2.imread(image_path)\n",
    "#   plt.imshow(img)\n",
    "#   plt.show()\n",
    "\n",
    "    ### resize ###\n",
    "    resized=cv2.resize(img, fixed_size, interpolation=cv2.INTER_AREA)\n",
    "#   plt.imshow(resized)\n",
    "#   plt.show()\n",
    "\n",
    "    ### convert the image to grayscale ###\n",
    "    imgGray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)  \n",
    "#   cv2.imshow('title',imgGray)\n",
    "#   cv2.waitKey(0)\n",
    "#   cv2.destroyAllWindows()\n",
    "    return imgGray\n",
    "\n",
    "\n",
    "############### CREATION D'un Dataset à partir des images traitées ########################\n",
    "Data = [] # Data contient la matrice des pixels de l'image en ligne => 1 lignes = 1 images (par ex Image[0] : 1x(3136) si on fait resize 56par56 )\n",
    "Target_name = [] # Target_Name C'est la classe de chaque image sous forme ('jupe', 'robe', 't-shirt', 'pantalon')\n",
    "Data_name = [] # Data_name contient le nom de l'image  par exemple : jupe_01\n",
    "Image=[] #Image est une matrice de matrice => 1 ligne = 1 images en format matrice (par ex  Image[0] : 1x56x56\n",
    "\n",
    "def DataSet():\n",
    "    for category in CATEGORIES: \n",
    "        clothe_class=category[:-1]  #ie jupe, pantalon, robe or t-shirt\n",
    "        for image in os.listdir(DATADIR+category):  #image : nom de l'image ie jupe_0.jpg\n",
    "            image_path =os.path.join(DATADIR+category+'/'+image) # path = path de l'image\n",
    "            imgGray=traitement_image(image_path)\n",
    "            imgGray_flat=np.array(imgGray).flatten()\n",
    "            try:\n",
    "                Image.append(imgGray)\n",
    "                Target_name.append(clothe_class)\n",
    "                Data.append(imgGray_flat)\n",
    "                Data_name.append(image[:-4])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(Data), np.array(Target_name), np.array(Data_name), np.array(Image) \n",
    "\n",
    "def DataSetCreation(DataSet_name):\n",
    "    ## on crée le data set\n",
    "    Data, Target_name, Data_Name, Image = DataSet()  \n",
    "    \n",
    "    ## vérification des dimensions \n",
    "    print(Data.shape, Target_name.shape,Data_Name.shape,Image.shape)\n",
    "    \n",
    "    ### mélange des données avec shuffle ; unison c'est pour que tous les arrays soient mélanger de la même façon et q'uon garde la correspondace entre eux\n",
    "    Data, Target_name, Data_Name, Image = shuffle_arrays_unison(arrays=[Data, Target_name, Data_Name, Image], random_seed=0)\n",
    "   \n",
    "    ### encodage  pantalon to 1 ; jupe to 0 ;  t-shirt to 3 and robe to 2 pour chaque images \n",
    "    \n",
    "    Target=pd.Series(Target_name).astype('category').cat.codes\n",
    "    #print(Target)\n",
    "    \n",
    "    #### création d'un dictionnaire pour savoir la correspondance code <-> vetement \n",
    "    Target_name_list = dict(enumerate(pd.Series(Target_name).astype('category').cat.categories)) # ie {0: 'jupe', 1: 'pantalon', 2: 'robe', 3: 't-shirt'}\n",
    "#   print(Target_name_list) \n",
    "    ### Creation du data set sous forme d'un dictionnaire comme quand on load les dataset scikitlearn\n",
    "    DataSet_name={'data': Data,\n",
    "                        'target':Target,\n",
    "                        'target_names':Target_name,\n",
    "                        'target_name_list':list(Target_name_list.values()),\n",
    "                        'data_Name':Data_Name,\n",
    "                        'images': Image\n",
    "                       }\n",
    "    ### pour sauver le dataset et pouvoir le reloader plus tard dans un autre notebook\n",
    "    with open(str(DataSet_name)+\".pickle\",\"wb\") as outpout:\n",
    "        pickle.dump(DataSet_name, outpout)\n",
    "        \n",
    "    return DataSet_name\n",
    "    # # then you can load it back in another script.\n",
    "    # with open('ZARA_DataSet_wo_models.pickle', 'rb') as data:\n",
    "    #     ZARA_DataSet_wo_models = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZARA_DataSet_wo_models=DataSetCreation(ZARA_DataSet_wo_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZARA_DataSet_wo_models.keys()\n",
    "# Pour pouvoir utiliser les differents data du dataset sans avoir à écrire le nom du dataset à chaque fois \n",
    "for key in ZARA_DataSet_wo_models.keys():\n",
    "    globals()[str(key)] =ZARA_DataSet_wo_models[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
